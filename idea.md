# 🚀 "隔空绘手" 项目开发方案书

> **文档用途**：供 Claude Code 执行的完整开发指南
> **项目名称**：Air Canvas & Presenter
> **技术栈**：Python 3.10+ / OpenCV / MediaPipe / PyAutoGUI

---

## 一、项目概述

### 1.1 项目目标
构建一个基于手势识别的虚拟演示系统，用户可以通过摄像头捕捉手势来：
- 在屏幕上空中绘图
- 控制PPT翻页
- 实现AR增强标注效果（粒子特效、图形美化、掌心HUD）

### 1.2 核心技术原理
1. **MediaPipe Hands** 检测手部21个关键点
2. 根据关键点几何关系（距离、角度）识别手势类型
3. 将识别到的手势映射为具体操作

### 1.3 项目结构
```
air_canvas/
 main.py                 # 主程序入口
 config.py               # 全局配置
 requirements.txt        # 依赖
 core/                   # 核心模块
    hand_detector.py    # 手部检测
    gesture_recognizer.py # 手势识别
    coordinate_mapper.py  # 坐标映射
 modules/                # 功能模块
    canvas.py           # 画布
    virtual_pen.py      # 画笔
    ppt_controller.py   # PPT控制
    shape_recognizer.py # 图形识别
    particle_system.py  # 粒子系统
    palm_hud.py         # 掌心HUD
 utils/                  # 工具函数
     smoothing.py        # 平滑算法
```

---

## 二、阶段一：骨架搭建

### 2.1 目标
实现摄像头读取、手部关键点检测、用食指控制鼠标移动
### 2.2 任务清单

#### 任务 1.1：项目初始化
- 创建项目目录结构
- 创建 `requirements.txt`，包含：opencv-python, mediapipe, numpy, pyautogui
- 创建 `config.py`，定义所有配置参数（摄像头分辨率、屏幕分辨率、检测置信度、操作区域范围等）

#### 任务 1.2：实现手部检测器 (`core/hand_detector.py`)
- 封装 MediaPipe Hands
- 输入：BGR图像帧
- 输出：Hand数据类，包含：
  - `landmarks`: 21个关键点的像素坐标列表
- `landmarks_norm`: 21个关键点的归一化坐标(0-1)
  - `bbox`: 手部边界框
  - `handedness`: 左手/右手
- 提供辅助方法：计算两点距离、绘制关键点

**关键点索引常量**（需定义）：
```python
WRIST = 0
THUMB_TIP = 4
INDEX_TIP = 8
MIDDLE_TIP = 12
RING_TIP = 16
PINKY_TIP = 20
```

#### 任务 1.3：实现坐标映射器 (`core/coordinate_mapper.py`)
- **核心概念**：定义一个"操作区域"（如画面中心60%区域），只有手在此区域内才映射到全屏
- **原因**：避免用户手要伸到画面边缘才能触及屏幕边缘
- 输入：摄像头坐标
- 输出：屏幕坐标
- 包含简单的移动平均平滑，减少抖动

#### 任务 1.4：实现基础手势识别 (`core/gesture_recognizer.py`)
本阶段只需识别两种状态：
- **食指竖起**（其他手指弯曲） 移动模式
- **食指+中指竖起**  点击/暂停模式

判断手指是否竖起的逻辑：
```
如果 指尖y坐标 < 指根y坐标，则该手指竖起（图像坐标系y向下）
拇指特殊处理：比较x坐标
```

#### 任务 1.5：实现鼠标控制 (`main.py` 中整合)
- 当检测到食指竖起时，获取食指指尖坐标
- 通过坐标映射器转换为屏幕坐标
- 使用 `pyautogui.moveTo()` 移动鼠标

#### 任务 1.6：主程序框架
```python
# main.py 基本结构
while True:
    1. 读取摄像头帧
    2. 水平翻转（镜像）
    3. 检测手部
    4. 如果检测到手：
       - 识别手势
       - 如果是移动模式：映射坐标，移动鼠标
    5. 绘制UI信息（FPS、当前模式）
    6. 显示画面
    7. 按q退出
```

### 2.3 验收标准
- [x] 摄像头画面正常显示
- [x] 手部21个关键点正确绘制
- [x] 食指竖起时，鼠标跟随手指移动
- [x] 移动平滑，无明显抖动

---

## 三、阶段二：虚拟画笔

### 3.1 目标
实现空中绘图功能，支持不同颜色、粗细，支持橡皮擦

### 3.2 任务清单

#### 任务 2.1：实现画布模块 (`modules/canvas.py`)
- 创建一个与屏幕同尺寸的透明画布（全黑背景的numpy数组）
- 提供方法：
  - `draw_line(pt1, pt2, color, thickness)`: 画线
  - `erase(center, radius)`: 擦除（画黑色圆）
  - `clear()`: 清空画布
  - `get_canvas()`: 获取画布图像
  - `save(filename)`: 保存为图片

#### 任务 2.2：实现虚拟画笔 (`modules/virtual_pen.py`)
- 维护上一帧的绘制位置 `prev_point`
- 当处于绘画模式时：
  - 如果 `prev_point` 存在，从 `prev_point` 画线到当前点
  - 更新 `prev_point`
- 当退出绘画模式时：
- 重置 `prev_point = None`（避免跨段连线）
- 集成卡尔曼滤波平滑（可选，放在 `utils/smoothing.py`）

#### 任务 2.3：扩展手势识别
新增以下手势：
| 手势 | 判定条件 | 对应操作 |
|------|----------|----------|
| 捏合 | 食指尖与拇指尖距离 < 阈值(0.05) | 进入绘画模式 |
| 五指张开 | 5根手指全部竖起 | 橡皮擦模式 |
| 握拳 | 5根手指全部弯曲 | 切换到空闲模式 |

**重要**：使用滞后阈值防止边界抖动
```
捏合触发阈值: 0.05
捏合释放阈值: 0.08（需要拉开更远才释放）
```

#### 任务 2.4：实现橡皮擦 (`modules/eraser.py`)
- 当检测到五指张开时激活
- 跟踪手掌中心位置
- 在该位置绘制黑色圆形（即擦除）
#### 任务 2.5：画面融合显示
将画布叠加到摄像头画面上：
```python
# 方法1：简单叠加
mask = cv2.cvtColor(canvas, cv2.COLOR_BGR2GRAY) > 0
frame[mask] = canvas[mask]

# 方法2：半透明混合
frame = cv2.addWeighted(frame, 0.7, canvas, 0.3, 0)
```

#### 任务 2.6：画笔颜色/粗细调节（可选）
- 方案A：用另一只手的手势调节
- 方案B：特定手势循环切换颜色
- 方案C：UI按钮（后续阶段实现）

### 3.3 验收标准
- [x] 捏合手指时可以画线
- [x] 松开后再捏合，线条不会错误连接
- [x] 五指张开可以擦除
- [x] 握拳可以停止所有操作
- [x] 画布内容可保存为图片

---

## 四、阶段三：PPT控制与图形美化

### 4.1 目标
实现手势控制PPT翻页，将手绘图形自动美化为标准几何图形

### 4.2 任务清单

#### 任务 3.1：实现挥手检测 (`core/gesture_recognizer.py` 扩展)
- 记录手腕关键点最近15帧的位置
- 计算位移向量和速度
- 判定条件：
  - 水平位移 > 阈值(0.15) 且 速度 > 阈值  左右挥手
- 垂直位移 > 阈值 且 速度 > 阈值  上下挥手
- **关键**：添加冷却时间(20帧)，防止一次挥手触发多次
```python
# 挥手方向判定逻辑
dx = 最近5帧平均x - 最早5帧平均x
dy = 最近5帧平均y - 最早5帧平均y

if abs(dx) > abs(dy):  # 水平挥动
    if dx > threshold: return "SWIPE_RIGHT"
    if dx < -threshold: return "SWIPE_LEFT
"else:  # 垂直挥动
    if dy < -threshold: return "SWIPE_UP"
    if dy > threshold: return "SWIPE_DOWN"
```

#### 任务 3.2：实现PPT控制器 (`modules/ppt_controller.py`)
- 方案A（通用）：使用 `pyautogui.press('right')` / `press('left')` 模拟键盘
- 方案B（Windows增强）：使用 `pywin32` 直接控制 PowerPoint COM接口
- 方案C（macOS增强）：使用 AppleScript

手势映射：
| 手势 | 操作 |
|------|------|
| 向右挥手 | 下一页 
|| 向左挥手 | 上一页 |
| 向上挥手 | 第一页 (Home键) |
| 向下挥手 | 最后一页 (End键) |

#### 任务 3.3：实现图形识别器 (`modules/shape_recognizer.py`)
**触发时机**：当用户结束绘画（捏合松开）的瞬间

**识别流程**：
1. 获取刚才绘制的所有点
2. 计算几何特征：
   - 封闭度 = 起点终点距离 / 轨迹总长度
- 使用 `cv2.approxPolyDP` 多边形拟合，获取顶点数
   - 使用 `cv2.minEnclosingCircle` 计算圆形度
3. 根据特征判断图形类型：
   - 顶点数=3 且 封闭  三角形
   - 顶点数=4 且 封闭  矩形
   - 圆形度>0.8 且 封闭  圆形
   - 不封闭 且 有尖端  箭头
   - 其他  保持原样

**美化逻辑**：
```python
if shape == "circle":
    清除原笔迹
    在同位置绘制标准圆 cv2.circle()
elif shape == "rectangle":
    清除原笔迹
    绘制标准矩形 cv2.rectangle()
# ...以此类推
```

#### 任务 3.4：显示PPT页码信息
- 在界面角落显示 "Slide: 3/10" 格式
- Windows下可通过COM接口获取真实页码
- 通用方案：仅显示翻页次数计数

### 4.3 验收标准
- [x] 向右挥手触发下一页，向左触发上一页
- [x] 挥手不会连续误触发
- [x] 画一个大致的圆，松手后自动变成标准圆
- [x] 画一个大致的矩形，松手后自动变成标准矩形
---

## 五、阶段四：AR增强与粒子特效

### 5.1 目标
实现视觉增强效果：粒子拖尾、激光笔、掌心HUD

### 5.2 任务清单

#### 任务 4.1：实现粒子系统 (`modules/particle_system.py`)
**数据结构**：
```python
Particle:
    - position: (x, y)
    - velocity: (vx, vy)
    - lifetime: float (剩余寿命)
    - color: (b, g, r)
    - size: float
```

**核心逻辑**：
1. **发射**：当手指移动时，在指尖位置生成5-10个粒子
2. **更新**（每帧）：
   - 位置 += 速度
- 速度.y += 重力(0.1)
   - 寿命 -= dt
   - 大小 *= 0.98
3. **渲染**：绘制所有存活粒子（带发光效果）
4. **回收**：移除寿命<=0的粒子
**性能优化**：使用NumPy数组批量计算，而非逐个粒子循环

#### 任务 4.2：实现激光笔 (`modules/laser_pointer.py`)
- 当食指竖起时激活
- 在食指指尖位置绘制：
  - 内圈：红色实心圆 (半径5)
  - 外圈：半透明红色光晕 (半径15)
- 光晕效果：使用 `cv2.GaussianBlur` 或叠加多个透明圆

```python
# 简单光晕效果
cv2.circle(frame, pos, 15, (0, 0, 150), -1)  # 外层暗红
cv2.circle(frame, pos, 8, (0, 0, 200), -1)   # 中层
cv2.circle(frame, pos, 4, (0, 0, 255), -1)   # 内层亮红
```

#### 任务 4.3：实现掌心HUD (`modules/palm_hud.py`)
**显示内容**：
- 当前时间
- 演讲计时器
- 可自定义文本

**实现步骤**：
1. 检测手掌是否张开且静止(1秒以上)
2. 计算手掌中心点（手腕、食指根、小指根的中心）
3. 创建半透明信息图层
4. 使用透视变换使信息"贴合"手掌平面
5. Alpha混合叠加到画面
**简化方案**（如果透视变换太复杂）：
直接在手掌中心位置绘制固定朝向的信息框即可

#### 任务 4.4：整合所有特效到主程序
- 在主循环中按顺序调用：
  1. 手部检测
  2. 手势识别
  3. 执行对应操作（画笔/PPT/橡皮擦）
  4. 更新粒子系统
  5. 渲染画布
  6. 渲染粒子
  7. 渲染激光笔
  8. 渲染掌心HUD
  9. 显示UI信息

#### 任务 4.5：添加UI控制面板（可选）
- 使用OpenCV的trackbar或简单按钮
- 功能：切换颜色、调节粗细、开关粒子效果
### 5.3 验收标准
- [x] 绘画时有粒子拖尾效果
- [x] 食指指向时有激光笔效果
- [x] 手掌静止时显示时间信息
- [x] 帧率保持在25FPS以上

---

## 六、关键技术要点

### 6.1 手势识别防抖
**问题**：手势过渡态容易误触发
**解决**：
1. 使用手势缓冲区，统计最近10帧
2. 只有超过7帧一致才确认切换
3. 使用滞后阈值（触发阈值 < 释放阈值）

### 6.2 坐标平滑
**问题**：手部检测有噪声导致抖动
**解决**：
1. 简单方案：移动平均滤波
2. 进阶方案：卡尔曼滤波

### 6.3 挥手冷却
**问题**：一次挥手触发多次翻页
**解决**：触发后设置冷却期(20帧)，冷却期内忽略挥手

### 6.4 画布融合
**问题**：画布遮挡摄像头画面
**解决**：只叠加非黑色部分，或使用透明度混合

---

## 七、配置参数汇总

```python
# config.py 关键参数

# 摄像头
CAMERA_ID = 0
CAMERA_WIDTH = 1280
CAMERA_HEIGHT = 720

# 屏幕（根据实际屏幕调整）
SCREEN_WIDTH = 1920
SCREEN_HEIGHT = 1080

# 操作区域（画面中心70%区域）
ACTIVE_REGION = (0.15, 0.15, 0.85, 0.85)

# 手势阈值
PINCH_THRESHOLD = 0.05
PINCH_RELEASE_THRESHOLD = 0.08
SWIPE_THRESHOLD = 0.15
SWIPE_COOLDOWN = 20

# 画笔
PEN_COLOR = (0, 255, 255)  # BGR黄色
PEN_THICKNESS = 3
ERASER_SIZE = 30

# 平滑系数
SMOOTHING_FACTOR = 0.4

# 粒子
MAX_PARTICLES = 300
PARTICLE_EMIT_COUNT = 5
```

---

## 八、依赖安装

```bash
pip install opencv-python mediapipe numpy pyautogui
# Windows额外安装（PPT控制增强）
pip install pywin32
```

---

## 九、执行顺序建议

1. **先完成阶段一**，确保手部检测和鼠标控制正常工作
2. **再完成阶段二**，实现基础画笔功能
3. **然后阶段三**，添加PPT控制和图形美化
4. **最后阶段四**，添加视觉增强效果

每个阶段完成后进行测试，确保功能正常再进入下一阶段。
---

## 十、测试用例

### 阶段一测试
- [ ] 运行程序，摄像头画面正常显示
- [ ] 举起手，21个绿色关键点正确显示
- [ ] 竖起食指，鼠标跟随移动

### 阶段二测试
- [ ] 捏合拇指食指，在空中画线，屏幕出现线条
- [ ] 松开再捏合，新线条不会与旧线条连接
- [ ] 五指张开移动，可以擦除线条
- [ ] 握拳，停止所有绘画操作

### 阶段三测试
- [ ] 向右快速挥手，PPT翻到下一页
- [ ] 快速连续挥手，只触发一次翻页
- [ ] 画一个歪歪的圆，松手后变成标准圆

### 阶段四测试
- [ ] 画线时有彩色粒子拖尾
- [ ] 竖起食指时，指尖有红色激光点
- [ ] 张开手掌静止1秒，掌心显示当前时间

---

**文档结束**
